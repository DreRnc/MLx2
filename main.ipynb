{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from data.load_data import load_monk\n",
    "from src.MetricFunctions import get_metric_instance\n",
    "from src.MLP import MLP\n",
    "from src.GridSearch import GridSearch, RandomGridsearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.EarlyStopping import EarlyStopping\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from data.load_data import load_monk\n",
    "from src.MetricFunctions import get_metric_instance\n",
    "from src.MLP import MLP\n",
    "from src.GridSearch import GridSearch, RandomGridsearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.EarlyStopping import EarlyStopping\n",
    "path = os.getcwd()\n",
    "file = '/data/ML-CUP22-TR.csv'\n",
    "\n",
    "labels = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','y1','y2']\n",
    "\n",
    "TR = pd.read_csv(path + file, sep = ',', header = None, usecols=range(1,12), \\\n",
    "                 names = labels, skiprows = 7)\n",
    "\n",
    "TR = TR.to_numpy()\n",
    "\n",
    "np.random.shuffle(TR)\n",
    "\n",
    "TR = np.split(TR, [9], axis = 1)\n",
    "\n",
    "X = TR[0]\n",
    "y_true = TR[1]\n",
    "\n",
    "print(y_true)\n",
    "print(X.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.1)\n",
    "params_grid = {\n",
    "    \"eta\": [0.35, 0.25, 0.2, 0.15, 0.1],\n",
    "    \"l2\": [0.0005, 0.0004, 0.0003, 0.0002, 0.0001],\n",
    "    \"alpha\": [0.25, 0.4, 0.5, 0.6, 0.75],\n",
    "    \"minibatch_size\": [None, 150]\n",
    "}\n",
    "\n",
    "mlp = MLP([10,60], 9, 2, task = \"regression\", activation_function = \"sigmoid\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "for i in range(5):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.1)\n",
    "  # sandardise X_train and X_test\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "  Parameters =  {'n_epochs': 5000, 'batch_size': 500, 'patience': 4, 'early_stopping': False,\n",
    "  'Nesterov': False, 'weights_initialization': 'xavier', 'verbose': False, 'step': 0.001, 'momentum': 0.75,\n",
    "    'regularization': 'no', 'tolerance': 1e-5, 'alpha_l2': 0.2, 'alpha_l1': 0.01}\n",
    "\n",
    "  mlp = MLP([10,60], 9, 2, task = \"regression\", activation_function = \"relu\")\n",
    "\n",
    "  mlp.fit(X_train, y_train, n_epochs= 5000, batch_size= 500, patience= 50, early_stopping= True,\n",
    "  Nesterov = False, weights_initialization = 'scaled', verbose = False, step= 0.001, momentum= 0.75,\n",
    "    regularization = 'no', tolerance= 1e-5, alpha_l2= 0.2, alpha_l1= 0.01)\n",
    "\n",
    "  #mlp.fit(X_train, y_train, n_epochs = 500, batch_size = 500, error = \"MSE\", step = 0.1)\n",
    "\n",
    "  y_pred = mlp.predict(X_test)\n",
    "\n",
    "  mse = get_metric_instance(\"mse\")\n",
    "  err.append(mse(y_test, y_pred))\n",
    "  plt.plot(mlp.learning_curve[100:], color = 'blue')\n",
    "  plt.plot(mlp.validation_curve[100:], color = 'red')\n",
    "  plt.title(\"Learning curve\")\n",
    "  print(mse(y_test, y_pred))\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "print(err)\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp.learning_curve[100:], color = 'blue')\n",
    "plt.plot(mlp.validation_curve[100:], color = 'red')\n",
    "plt.title(\"Learning curve\")\n",
    "print(mse(y_test, y_pred))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "\n",
    "for step in [0.005, 0.01, 0.05, 0.1]:\n",
    "    mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 50, step = step)\n",
    "    ax.plot(range(n_epochs), mlp.learning_curve, label = 'step = ' + str(step), linewidth = 1)\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')  \n",
    "ax.set_title(\"Learning curves with different values of the learning rate\")  \n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.1\n",
    "for alpha_l2 in [0, 0.005, 0.01, 0.05, 0.1]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 50, step = step, regularization = \"L2\", alpha_l2 = alpha_l2)\n",
    "    ax.plot(range(n_epochs), learning_curve, label = 'alpha L2 = ' + str(alpha_l2), linewidth = 1)\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')  \n",
    "ax.set_title(\"Learning curves with different regularization\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.5\n",
    "for momentum in [0, 0.1, 0.3]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum)\n",
    "    ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')   \n",
    "ax.set_title(\"Learning curves with different momentum\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.1\n",
    "for batch_size in [1, 100]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = batch_size, step = step)\n",
    "    ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'batch_size = ' + str(batch_size))\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')   \n",
    "ax.set_title(\"Learning curves with different batch size\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.5\n",
    "\n",
    "momentum = 0\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "momentum = 0.2\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum, Nesterov = True)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum) + ' (Nesterov)')\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "input_size = 5\n",
    "mlp = MLP([5, 5], input_size, n_classes, task = \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (v3.10.8:aaaf517424, Oct 11 2022, 10:14:40) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed0be3fc2c904159af230147fb8c5b6a9503599b122f9148b8936b9beff70f89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
