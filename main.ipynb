{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from data.load_data import load_monk\n",
    "from src.MetricFunctions import get_metric_instance\n",
    "from src.MLP import MLP\n",
    "from src.GridSearch import GridSearch, RandomGridsearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.EarlyStopping import EarlyStopping\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.load_data import load_monk\n",
    "path = os.getcwd()\n",
    "file = '/data/monks-1.train'\n",
    "file_test = '/data/monks-1.test'\n",
    "\n",
    "labels = ['class','x1','x2','x3','x4','x5','x6']\n",
    "\n",
    "\n",
    "X_train, y_train = load_monk(path+file, labels)\n",
    "X_test, y_test = load_monk(path+file_test, labels)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP([4], 17, 1, task = \"classification\", activation_function = \"relu\")\n",
    "\n",
    "mlp.fit(X_train, y_train, n_epochs = 1500, batch_size = 50, error = \"NLL\", step = 0.2, regularization = 'no', momentum = 0,\n",
    "        early_stopping = False, verbose = True)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "acc = get_metric_instance(\"accuracy\")\n",
    "print(acc(y_test, y_pred))\n",
    "plt.plot(mlp.learning_curve)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from data.load_data import load_monk\n",
    "from src.MetricFunctions import get_metric_instance\n",
    "from src.MLP import MLP\n",
    "from src.GridSearch import GridSearch, RandomGridsearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.EarlyStopping import EarlyStopping\n",
    "path = os.getcwd()\n",
    "file = '/data/ML-CUP22-TR.csv'\n",
    "\n",
    "labels = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','y1','y2']\n",
    "\n",
    "TR = pd.read_csv(path + file, sep = ',', header = None, usecols=range(1,12), \\\n",
    "                 names = labels, skiprows = 7)\n",
    "\n",
    "TR = TR.to_numpy()\n",
    "\n",
    "np.random.shuffle(TR)\n",
    "\n",
    "TR = np.split(TR, [9], axis = 1)\n",
    "\n",
    "X = TR[0]\n",
    "y_true = TR[1]\n",
    "\n",
    "print(y_true)\n",
    "print(X.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "for i in range(2):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.1)\n",
    "  # sandardise X_train and X_test\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "  Parameters =  {'n_epochs': 15000, 'batch_size': 500, 'patience': 50, 'early_stopping': True,\n",
    "  'Nesterov': False, 'weights_initialization': 'xavier', 'verbose': False, 'step': 0.001, 'momentum': 0.75,\n",
    "    'regularization': 'no', 'tolerance': 0.0001, 'alpha_l2': 0.2, 'alpha_l1': 0.01}\n",
    "\n",
    "  mlp = MLP([10,60], 9, 2, task = \"regression\", activation_function = \"relu\")\n",
    "\n",
    "  mlp.fit(X_train, y_train, n_epochs= 5000, batch_size= 500, patience= 50, early_stopping= True,\n",
    "  Nesterov = False, weights_initialization = 'scaled', verbose = False, step= 0.001, momentum= 0.75,\n",
    "    regularization = 'no', tolerance= 0.001, alpha_l2= 0.2, alpha_l1= 0.01)\n",
    "\n",
    "  #mlp.fit(X_train, y_train, n_epochs = 500, batch_size = 500, error = \"MSE\", step = 0.1)\n",
    "\n",
    "  y_pred = mlp.predict(X_test)\n",
    "\n",
    "  mse = get_metric_instance(\"mse\")\n",
    "  err.append(mse(y_test, y_pred))\n",
    "  plt.plot(mlp.learning_curve[100:])\n",
    "  plt.plot(mlp.validation_curve[100:])\n",
    "  plt.title(\"Learning curve\")\n",
    "  print(mse(y_test, y_pred))\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "print(err)\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "\n",
    "for step in [0.005, 0.01, 0.05, 0.1]:\n",
    "    mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 50, step = step)\n",
    "    ax.plot(range(n_epochs), mlp.learning_curve, label = 'step = ' + str(step), linewidth = 1)\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')  \n",
    "ax.set_title(\"Learning curves with different values of the learning rate\")  \n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.1\n",
    "for alpha_l2 in [0, 0.005, 0.01, 0.05, 0.1]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 50, step = step, regularization = \"L2\", alpha_l2 = alpha_l2)\n",
    "    ax.plot(range(n_epochs), learning_curve, label = 'alpha L2 = ' + str(alpha_l2), linewidth = 1)\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')  \n",
    "ax.set_title(\"Learning curves with different regularization\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.5\n",
    "for momentum in [0, 0.1, 0.3]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum)\n",
    "    ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')   \n",
    "ax.set_title(\"Learning curves with different momentum\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.1\n",
    "for batch_size in [1, 100]:\n",
    "    learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = batch_size, step = step)\n",
    "    ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'batch_size = ' + str(batch_size))\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')   \n",
    "ax.set_title(\"Learning curves with different batch size\")  \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), layout='constrained')\n",
    "step = 0.5\n",
    "\n",
    "momentum = 0\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "momentum = 0.2\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum))\n",
    "\n",
    "learning_curve = mlp.fit(X, y_true, n_epochs = n_epochs, batch_size = 100, step = step, momentum = momentum, Nesterov = True)\n",
    "ax.plot(range(n_epochs), learning_curve, linewidth = 1, label = 'momentum = ' + str(momentum) + ' (Nesterov)')\n",
    "\n",
    "ax.set_xlabel('epoch')  \n",
    "ax.set_ylabel('training error (MSE)')    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "input_size = 5\n",
    "mlp = MLP([5, 5], input_size, n_classes, task = \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a84d6694d99063d2bb0286ebc4a83b7a5fbbe8812bdd85c9b7227af9c494503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
